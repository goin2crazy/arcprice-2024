{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8876241,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class Config: \n    \"\"\"\n    In this competition the matrix size is from 2x2 to 30x30\n    and maximum 5-6 examples of solutions \n    \"\"\"\n    \n    \n    train = {'inputs': '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json',\n             'outputs': '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'}\n    validation = {'inputs': '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json', \n                  'outputs': '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'}\n    test = {'inputs': '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'}\n    \ncfg = Config() ","metadata":{"execution":{"iopub.status.busy":"2024-06-22T17:03:33.721328Z","iopub.execute_input":"2024-06-22T17:03:33.721682Z","iopub.status.idle":"2024-06-22T17:03:33.766257Z","shell.execute_reply.started":"2024-06-22T17:03:33.721649Z","shell.execute_reply":"2024-06-22T17:03:33.765146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport json \n\nfrom tensorflow.data import Dataset \nimport tensorflow as tf \n\nfrom tensorflow.keras import layers \nfrom tensorflow.keras.optimizers import AdamW ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-22T17:03:33.768014Z","iopub.execute_input":"2024-06-22T17:03:33.768369Z","iopub.status.idle":"2024-06-22T17:03:50.794669Z","shell.execute_reply.started":"2024-06-22T17:03:33.768338Z","shell.execute_reply":"2024-06-22T17:03:50.793562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation ","metadata":{}},{"cell_type":"code","source":"def prepare_inputs(path): \n    with open(path, mode='r') as file: \n        return json.load(file)\n    \ndef prepare_outputs(path): \n    with open(path, mode='r') as file: \n        return json.load(file)\n\ndef prepare1(data_path_item): \n    inp = 'inputs'\n    out = 'outputs'\n    r = dict() \n    \n    if inp in data_path_item: \n        inputs = data_path_item[inp]\n        \n        r['inputs'] = prepare_inputs(inputs)\n        \n    if out in data_path_item: \n        outputs = data_path_item[out]\n        \n        r['outputs'] = prepare_outputs(outputs)\n        \n    return r \n\ntrain = prepare1(cfg.train)\nvalidation = prepare1(cfg.validation)\n# test = prepare1(cfg.test)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T17:03:50.796147Z","iopub.execute_input":"2024-06-22T17:03:50.796974Z","iopub.status.idle":"2024-06-22T17:03:51.299481Z","shell.execute_reply.started":"2024-06-22T17:03:50.796931Z","shell.execute_reply":"2024-06-22T17:03:51.298297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ex = list(train['inputs'].values())[10]","metadata":{"execution":{"iopub.status.busy":"2024-06-22T17:37:31.804305Z","iopub.execute_input":"2024-06-22T17:37:31.805558Z","iopub.status.idle":"2024-06-22T17:37:31.812004Z","shell.execute_reply.started":"2024-06-22T17:37:31.805472Z","shell.execute_reply":"2024-06-22T17:37:31.810618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 \n\ndef size_to_30(i):\n    arr = np.array(i['input'])\n    # Convert arr to cv2 image (assuming arr is in a format compatible with OpenCV)\n    img = arr.astype(np.uint8)\n    # Resize the image to 30x30 using cubic interpolation\n    img_resized = cv2.resize(img, dsize=(100, 100), interpolation=cv2.INTER_NEAREST)\n    # Convert the resized image back to a NumPy array\n    return img_resized\n\n\n# Assuming ex['test'] contains the original arrays in 'input' field\noriginal = [np.array(i['input']) for i in ex['test']]\nresized = [size_to_30(i) for i in ex['test']]\n\n# Visualize the original image\nplt.imshow(original[0], cmap='gray')\n# plt.set_title('Original')\n# plt.axis('off')\nplt.show() \n\n# Visualize the resized image\nplt.imshow(resized[0], cmap='gray')\n# plt.set_title('Resized (30x30)')\n# plt.axis('off')\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T17:37:33.919309Z","iopub.execute_input":"2024-06-22T17:37:33.919799Z","iopub.status.idle":"2024-06-22T17:37:34.368943Z","shell.execute_reply.started":"2024-06-22T17:37:33.919762Z","shell.execute_reply":"2024-06-22T17:37:34.367709Z"},"trusted":true},"execution_count":null,"outputs":[]}]}